{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15a305f-1cb1-4ca2-9d8d-efc77f769680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator # For evaluating the recommendation\n",
    "from pyspark.ml.recommendation import ALS # Pyspark implementation of Collaborative filtering\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # To ignore warnings in Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa47638-2ebd-43eb-b9d4-8139d55af1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/17 11:38:08 WARN Utils: Your hostname, ubuntuonm1 resolves to a loopback address: 127.0.1.1; using 192.168.64.2 instead (on interface enp0s1)\n",
      "24/04/17 11:38:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/17 11:38:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('recommender').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8266fa-7f94-4c88-b2cf-4985c95d56ca",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "We will use famous MovieLens dataset, which is one of the most common datasets used when implementing and testing recommender engines. It contains 100k movie ratings from 943 users and a selection of 1682 movies.\n",
    "\n",
    "We can then read in the **u.data** file, which contains the full dataset. You can read a brief description of the dataset [here](http://files.grouplens.org/datasets/movielens/ml-100k-README.txt).\n",
    "\n",
    "You can download the dataset [here](http://files.grouplens.org/datasets/movielens/ml-100k.zip) or just use the u.data file that is already included in this folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "469abbf3-0a99-4b3b-8ab4-b93b118d90a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        0       50       5  881250949\n",
       "1        0      172       5  881250949\n",
       "2        0      133       1  881250949\n",
       "3      196      242       3  881250949\n",
       "4      186      302       3  891717742"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('u.data', sep='\\t', names=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73aa507-b9e2-4bec-9c18-1cee5637be60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id              title\n",
       "0        1   Toy Story (1995)\n",
       "1        2   GoldenEye (1995)\n",
       "2        3  Four Rooms (1995)\n",
       "3        4  Get Shorty (1995)\n",
       "4        5     Copycat (1995)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles = pd.read_csv(\"Movie_Id_Titles\") # Reading movies titile data for merding them with the rating data\n",
    "movie_titles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ea273-a4c1-42a0-83b3-1818920163b7",
   "metadata": {},
   "source": [
    "Merging movie titles from 'Movie_Id_Titles.csv' onto the main dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f33ab7-5445-46a5-9933-ee516d403a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>880473582</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>891271545</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>888552084</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>879362124</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp             title\n",
       "0        0       50       5  881250949  Star Wars (1977)\n",
       "1      290       50       5  880473582  Star Wars (1977)\n",
       "2       79       50       4  891271545  Star Wars (1977)\n",
       "3        2       50       5  888552084  Star Wars (1977)\n",
       "4        8       50       5  879362124  Star Wars (1977)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df,movie_titles,on='item_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f98cb7b-4fd2-4d04-b20a-1fb5533acd67",
   "metadata": {},
   "source": [
    "We can check user ids and the number of users in the data for getting an understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "211d9b7a-af69-489b-83e8-479a5657c655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0, 290,  79,   2,   8, 274, 227,  99, 305, 108,  63, 234,  97,\n",
       "       117,  70, 318, 145, 124, 253, 271, 254, 326, 213,  80, 322,  28,\n",
       "       267, 130, 262, 230, 316, 327, 299, 144, 162,  48, 141, 251, 297,\n",
       "       137, 154, 257, 269, 123,  94, 330, 368,  77, 321, 381,  43, 286,\n",
       "       247,  68, 150, 214, 210, 158, 279, 288, 280,  25, 102, 209, 103,\n",
       "       398, 379, 409, 386, 407, 101, 201, 203, 283, 128, 200,  58,  54,\n",
       "       311,  96,   4, 401,  71,  59, 176, 393,  14,  12, 432, 378, 245,\n",
       "       115, 406, 444, 160,  23, 433, 125, 320, 438, 461, 250, 437, 119,\n",
       "        27, 275, 389, 445, 270, 422, 465, 467, 157, 276,  65,  10, 435,\n",
       "       458, 478,   6, 192, 387, 405, 287,  64, 369, 272, 394, 334, 346,\n",
       "       352, 177, 153,  62, 148, 325,  15, 456, 371, 506, 360, 509, 533,\n",
       "       454, 340, 239, 221, 215, 194,  45,   5, 479, 303, 494, 504, 347,\n",
       "       161, 313, 113, 453, 540, 402,  66, 523, 536, 527, 277, 549, 551,\n",
       "       530, 339,  49, 539, 581, 484, 294, 592, 463, 217,  87,  91, 417,\n",
       "       569, 498, 293,  46, 495, 385,  69, 248, 399, 528, 382, 151, 416,\n",
       "        37, 345, 470, 411, 244, 350, 623, 516, 430, 493, 624, 517, 370,\n",
       "       268, 324, 638, 563, 178, 618,  26, 642, 653, 354,  60, 644, 496,\n",
       "       184, 650,  30, 457, 343, 552, 600, 263, 662, 471, 602, 363, 541,\n",
       "       481, 421, 597, 503, 550, 521,  89, 629, 189, 672, 182, 622, 323,\n",
       "       582, 654, 682, 426, 619, 235, 608, 526, 698, 660,   1, 308, 637,\n",
       "       575, 694, 634, 474, 705, 169, 310, 499, 719, 594, 505, 490, 488,\n",
       "       557,  72, 537, 296, 721, 704, 175, 655, 730, 482,  21, 429, 676,\n",
       "       736, 233, 758, 710, 674, 413, 500, 757, 116,  13, 593, 708, 373,\n",
       "        55, 424, 395, 374, 663, 573, 524, 706, 691, 711, 174, 475, 104,\n",
       "       751, 576, 794, 700, 236, 610, 513, 678,  53, 703, 487, 367, 768,\n",
       "       714,  42, 659, 630, 301, 799, 198, 797, 564, 658, 761, 132, 231,\n",
       "       216, 826, 746, 835, 862, 791, 292,  85, 727, 825, 392, 760, 419,\n",
       "       337, 864, 748, 701, 744, 643, 753,  92, 833,  51, 747, 265, 717,\n",
       "       397, 851, 295, 669, 880, 514, 883, 561, 830, 632, 664, 844,  56,\n",
       "       641, 789, 891, 507, 697, 742, 881, 466, 716, 871,  44, 831, 931,\n",
       "       391, 846, 468,  82, 934, 815, 256, 902, 298, 450, 665, 917, 869,\n",
       "       776, 919, 689, 567, 512, 878, 834, 867, 796,   9, 868, 480, 344,\n",
       "       329, 806, 671, 649, 249, 380, 621, 185, 455, 606, 699, 127, 483,\n",
       "       839, 790, 312, 121, 916, 679, 668, 922, 892, 232, 246, 436, 222,\n",
       "       452, 854, 895, 548, 897,  57, 852, 546, 709,  22, 765, 936, 805,\n",
       "       766, 770, 580, 613, 882, 875, 459, 291, 712, 899, 562, 555, 889,\n",
       "       595, 896, 586, 684, 763, 601, 942, 741, 756, 890, 633, 840, 359,\n",
       "       735, 447, 843, 850, 188, 745, 764, 738, 680, 553, 603, 554, 870,\n",
       "       804, 328, 773, 197,  18,  32, 566, 645,  20, 577, 486, 823, 759,\n",
       "       579, 879,   7, 940, 793, 938, 625, 910, 894, 620, 901, 798, 332,\n",
       "       781, 908, 848, 885, 686, 795, 807, 183, 425, 786, 937, 887, 666,\n",
       "       588, 596, 907, 933, 464,  95,  41, 545, 109, 715, 913, 403, 723,\n",
       "       538,  83, 307, 472, 542, 924, 929, 930, 560, 535, 923, 800, 336,\n",
       "       508, 693, 661, 361, 921, 120, 832, 943, 782, 785, 893, 584, 847,\n",
       "       838, 774, 771, 497, 779, 648, 734, 749, 886, 739, 903, 780, 204,\n",
       "       202, 225, 412,  76, 627, 591,  16, 767, 849, 118, 912, 556, 259,\n",
       "       932, 442, 707, 492, 911, 928, 114, 788, 207, 331, 167, 338,  38,\n",
       "       342, 138, 152, 522, 605,  90, 683, 918, 731, 196, 226, 306,  34,\n",
       "        35, 199, 173, 309, 111, 439, 355, 131, 451, 532, 181, 639, 520,\n",
       "       617,  86, 651, 460, 129,  40, 740, 733, 568, 673, 205, 440, 139,\n",
       "       628, 473, 695, 206, 863, 866, 803, 240, 898, 485, 574, 724, 428,\n",
       "       861, 408, 195, 743, 675, 845, 720, 186, 191, 190,  31, 100, 315,\n",
       "        88, 282, 208, 112, 126, 319,  47, 146, 171, 107, 229, 427,  29,\n",
       "       420, 241, 383, 418, 179, 362, 149, 285, 489, 390, 140, 446, 404,\n",
       "       423,   3, 375, 570, 105, 414, 531, 515, 685, 543, 384, 431, 762,\n",
       "       134, 640,  52,  74, 364, 818, 284, 853, 755, 828, 388, 808, 448,\n",
       "       787, 713, 775, 865, 696, 809, 802, 615, 547, 827, 752, 656, 920,\n",
       "       657, 819, 905, 801, 626, 860, 278, 688, 587, 926, 877, 784, 841,\n",
       "       842,  39, 836, 820, 616, 915, 772, 611, 544, 812, 147, 874, 635,\n",
       "       314, 224,  11, 690, 166, 156, 133, 511, 142, 631, 646, 353, 702,\n",
       "       783, 578, 519, 462, 729,  73, 237, 469, 607, 900, 737, 670,  84,\n",
       "       218, 135, 583, 559, 778, 193, 159, 264, 110, 914, 904, 476, 477,\n",
       "       106, 187, 243, 212, 667, 585, 855, 122, 829, 565, 884, 449, 909,\n",
       "       211, 168, 300,  78, 501, 223, 647, 726, 525, 652, 935, 238, 859,\n",
       "       927, 941, 692, 136, 939, 718, 219, 599, 590,  93, 357,  81, 165,\n",
       "       289, 365, 518, 636, 396, 255, 164, 180, 677, 572, 769, 837,  75,\n",
       "       817,  17, 376, 534, 434, 821, 872, 888, 304,  24, 571, 348, 349,\n",
       "       612, 722, 754, 792,  67, 242, 252, 441, 614, 777, 609, 822, 728,\n",
       "       906, 163, 604, 366, 377, 814, 372,  50, 333, 228, 925,  98, 172,\n",
       "       261,  61, 400, 281, 170, 681, 811, 824, 810, 273, 750, 589, 813,\n",
       "       351, 732, 857, 443, 155, 529, 856, 858,  19, 258, 220, 816, 491,\n",
       "       725, 558, 266, 415, 260, 302, 317, 335, 510, 356, 143, 341,  36,\n",
       "       687, 502, 876,  33, 358, 410, 598, 873])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of users:', df['user_id'].nunique())\n",
    "df['user_id'].unique()  # Unique users in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2915ee4-efce-462c-b99b-2b4842dfbd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ids selected for testing/evaluation of the model: [359, 162, 62, 243, 767, 421, 841, 546, 358, 847]\n"
     ]
    }
   ],
   "source": [
    "test_users_id = random.sample(sorted(df['user_id'].unique()), 10) # Selected random 10 users for testing\n",
    "print('User ids selected for testing/evaluation of the model:',test_users_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d20010-ebb4-4176-b97e-1b278f50a0e4",
   "metadata": {},
   "source": [
    "### Creating a spark data frame and splitting data into tran and test data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "982cf510-cfd7-4e52-b15f-7b6464f602f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+----------------+\n",
      "|user_id|item_id|rating|timestamp|           title|\n",
      "+-------+-------+------+---------+----------------+\n",
      "|      0|     50|     5|881250949|Star Wars (1977)|\n",
      "|    290|     50|     5|880473582|Star Wars (1977)|\n",
      "|     79|     50|     4|891271545|Star Wars (1977)|\n",
      "|      2|     50|     5|888552084|Star Wars (1977)|\n",
      "|      8|     50|     5|879362124|Star Wars (1977)|\n",
      "|    274|     50|     5|878944679|Star Wars (1977)|\n",
      "|    227|     50|     4|879035347|Star Wars (1977)|\n",
      "|     99|     50|     5|885679998|Star Wars (1977)|\n",
      "|    305|     50|     5|886321799|Star Wars (1977)|\n",
      "|    108|     50|     4|879879739|Star Wars (1977)|\n",
      "|     63|     50|     4|875747292|Star Wars (1977)|\n",
      "|    234|     50|     4|892079237|Star Wars (1977)|\n",
      "|     97|     50|     5|884239471|Star Wars (1977)|\n",
      "|    117|     50|     5|880126022|Star Wars (1977)|\n",
      "|     70|     50|     4|884064188|Star Wars (1977)|\n",
      "|    318|     50|     2|884495696|Star Wars (1977)|\n",
      "|    145|     50|     5|885557660|Star Wars (1977)|\n",
      "|    124|     50|     3|890287508|Star Wars (1977)|\n",
      "|    253|     50|     4|891628518|Star Wars (1977)|\n",
      "|    271|     50|     5|885848640|Star Wars (1977)|\n",
      "+-------+-------+------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(df.iloc[:,:]) # Spark dataframe containing all user data\n",
    "spark_df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c85a3772-940b-437c-bf04-3310a64017bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+----------------+\n",
      "|user_id|item_id|rating|timestamp|           title|\n",
      "+-------+-------+------+---------+----------------+\n",
      "|      0|     50|     5|881250949|Star Wars (1977)|\n",
      "|    290|     50|     5|880473582|Star Wars (1977)|\n",
      "|     79|     50|     4|891271545|Star Wars (1977)|\n",
      "|      2|     50|     5|888552084|Star Wars (1977)|\n",
      "|      8|     50|     5|879362124|Star Wars (1977)|\n",
      "|    274|     50|     5|878944679|Star Wars (1977)|\n",
      "|    227|     50|     4|879035347|Star Wars (1977)|\n",
      "|     99|     50|     5|885679998|Star Wars (1977)|\n",
      "|    305|     50|     5|886321799|Star Wars (1977)|\n",
      "|    108|     50|     4|879879739|Star Wars (1977)|\n",
      "|     63|     50|     4|875747292|Star Wars (1977)|\n",
      "|    234|     50|     4|892079237|Star Wars (1977)|\n",
      "|     97|     50|     5|884239471|Star Wars (1977)|\n",
      "|    117|     50|     5|880126022|Star Wars (1977)|\n",
      "|     70|     50|     4|884064188|Star Wars (1977)|\n",
      "|    318|     50|     2|884495696|Star Wars (1977)|\n",
      "|    145|     50|     5|885557660|Star Wars (1977)|\n",
      "|    124|     50|     3|890287508|Star Wars (1977)|\n",
      "|    253|     50|     4|891628518|Star Wars (1977)|\n",
      "|    271|     50|     5|885848640|Star Wars (1977)|\n",
      "+-------+-------+------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_spark_df = spark_df.filter(~spark_df.user_id.isin(test_users_id)) #Filtering the other users for creating training data\n",
    "train_spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9445c61a-e8a4-4f0e-877a-2151494806f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+--------------------+\n",
      "|user_id|item_id|rating|timestamp|               title|\n",
      "+-------+-------+------+---------+--------------------+\n",
      "|    162|     50|     5|877635662|    Star Wars (1977)|\n",
      "|     62|     50|     5|879372216|    Star Wars (1977)|\n",
      "|    421|     50|     5|892241294|    Star Wars (1977)|\n",
      "|    546|     50|     5|885140368|    Star Wars (1977)|\n",
      "|    359|     50|     5|886453271|    Star Wars (1977)|\n",
      "|    847|     50|     4|878774969|    Star Wars (1977)|\n",
      "|    767|    172|     5|891462614|Empire Strikes Ba...|\n",
      "|    421|    172|     5|892241707|Empire Strikes Ba...|\n",
      "|     62|    172|     5|879373794|Empire Strikes Ba...|\n",
      "|    847|    172|     4|878939803|Empire Strikes Ba...|\n",
      "|    847|    133|     3|878941027|Gone with the Win...|\n",
      "|    767|    242|     4|891462614|        Kolya (1996)|\n",
      "|     62|    302|     3|879371909|L.A. Confidential...|\n",
      "|    421|    302|     4|892241236|L.A. Confidential...|\n",
      "|    841|    302|     5|889066959|L.A. Confidential...|\n",
      "|    546|    346|     5|885139634| Jackie Brown (1997)|\n",
      "|    421|    474|     4|892241389|Dr. Strangelove o...|\n",
      "|     62|    474|     4|879373613|Dr. Strangelove o...|\n",
      "|    847|    474|     4|878941562|Dr. Strangelove o...|\n",
      "|    162|    474|     3|877636556|Dr. Strangelove o...|\n",
      "+-------+-------+------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_spark_df = spark_df.filter(spark_df.user_id.isin(test_users_id)) #Filtering the test users for creating test data\n",
    "test_spark_df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc51d03b-6ed7-4b1a-92ba-6bd1d5703693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|user_id|count|\n",
      "+-------+-----+\n",
      "|    243|   81|\n",
      "|    847|  146|\n",
      "|    421|   62|\n",
      "|    546|   59|\n",
      "|    841|   31|\n",
      "|     62|  232|\n",
      "|    162|   42|\n",
      "|    359|   27|\n",
      "|    767|   37|\n",
      "|    358|   43|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_spark_df.groupBy('user_id').count().show() # Count of movies each user rated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c2db39-f2d2-4bbe-aac1-571460e774c2",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "We can first implement training and evaluation code to set and understand the training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fd795e4-540a-4962-a355-bed527da4c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/17 11:38:18 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/04/17 11:38:18 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"user_id\", itemCol=\"item_id\", ratingCol=\"rating\", coldStartStrategy='drop')\n",
    "model = als.fit(train_spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639346da-8b07-4fd3-b559-1acdf55f44b5",
   "metadata": {},
   "source": [
    "### Get predictions on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2fe0e9b-345e-49e1-b47a-c470ba7d527c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+--------------------+----------+\n",
      "|user_id|item_id|rating|timestamp|               title|prediction|\n",
      "+-------+-------+------+---------+--------------------+----------+\n",
      "|    148|     50|     5|877016805|    Star Wars (1977)|  5.386224|\n",
      "|    463|     50|     4|890530818|    Star Wars (1977)|   3.61834|\n",
      "|    496|     50|     5|876072633|    Star Wars (1977)|  4.020207|\n",
      "|    471|     50|     3|889827757|    Star Wars (1977)| 3.1449816|\n",
      "|    833|     50|     2|875035718|    Star Wars (1977)| 3.4285824|\n",
      "|    148|    172|     5|877016513|Empire Strikes Ba...|  5.437351|\n",
      "|    496|    172|     5|876065558|Empire Strikes Ba...| 3.7307258|\n",
      "|    833|    172|     2|875224482|Empire Strikes Ba...| 3.2120566|\n",
      "|    471|    172|     4|889827822|Empire Strikes Ba...| 3.2251077|\n",
      "|    496|    133|     5|876066567|Gone with the Win...|   4.04644|\n",
      "|    148|    133|     5|877019251|Gone with the Win...| 4.4705496|\n",
      "|    463|    242|     2|889935629|        Kolya (1996)|  4.152084|\n",
      "|    463|    302|     5|877384835|L.A. Confidential...|  4.350955|\n",
      "|    833|    302|     3|884828670|L.A. Confidential...| 3.2591949|\n",
      "|    833|    346|     5|884828744| Jackie Brown (1997)|  3.546044|\n",
      "|    148|    474|     5|877019882|Dr. Strangelove o...|  4.588395|\n",
      "|    833|    474|     5|875122675|Dr. Strangelove o...| 4.7441936|\n",
      "|    471|    465|     5|889827822|Jungle Book, The ...| 4.4414926|\n",
      "|    833|    451|     1|875134016|       Grease (1978)|  0.893993|\n",
      "|    463|    257|     4|889935910| Men in Black (1997)|  3.231207|\n",
      "+-------+-------+------+---------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(train_spark_df, )\n",
    "predictions.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1826d60a-f923-4b1f-b557-303df42496d8",
   "metadata": {},
   "source": [
    "### Evaluation on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40cde662-a14e-4608-8c21-5aa1afa1a3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.7154468805153779\n"
     ]
    }
   ],
   "source": [
    "def evaluate_recommendation(recommendation_df):\n",
    "    \"\"\"Function for evaluating the recommendation predictions form the model. \n",
    "        Evaluation metrics calculated-\n",
    "            1.Root mean squared error of actual user ratings and predicted user ratings.\n",
    "            \n",
    "        Parameters:\n",
    "            recommendation_df(spark dataframe): Dataframe consisting of user rating and predicted ratings for each item/movie.\n",
    "        Return: None\n",
    "    \"\"\"\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "    rmse = evaluator.evaluate(recommendation_df)\n",
    "    print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "evaluate_recommendation(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b88ddc-099a-4a38-bac3-e93fc6906849",
   "metadata": {},
   "source": [
    "**Note:** The above predictions is done for training data. The evaluation should never be done on training data and should be done on test data. For this recommendation system, the user needs to give ratings for some movies(items) for collaborative filtering to work. This issue is common in recommendation systems especially in collaborative filtering and is also known as '*cold start problem*'.\n",
    "\n",
    "**Cold start issue:** Occurs when a new user or a new item enters the system, and there is not enough data or feedback to generate accurate and personalized recommendations. This constitutes a problem mainly for collaborative filtering algorithms due to the fact that they rely on the item's interactions to make recommendations.\n",
    "\n",
    "To solve this issue we will take some samples for each user in the test data and add it to the training data and fit the model again for getting recommendations of other movies for that users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d83a1b1-dbc9-4ff7-903e-9be5b13ab3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+--------------------+\n",
      "|user_id|item_id|rating|timestamp|               title|\n",
      "+-------+-------+------+---------+--------------------+\n",
      "|    359|      1|     4|886453214|    Toy Story (1995)|\n",
      "|    359|    273|     4|886453325|         Heat (1995)|\n",
      "|    359|    405|     3|886453354|Mission: Impossib...|\n",
      "|    359|      7|     5|886453325|Twelve Monkeys (1...|\n",
      "|    359|    298|     5|886453354|     Face/Off (1997)|\n",
      "|    359|    748|     3|886453271|   Saint, The (1997)|\n",
      "|    359|    121|     4|886453373|Independence Day ...|\n",
      "|    359|    295|     3|886453325|    Breakdown (1997)|\n",
      "+-------+-------+------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def split_test_to_input_true(test_spark_df, user_id, split_ratio=(0.2,0.8)):\n",
    "    '''Here we take the random samples for each user and split them in input samples and test samples, \n",
    "        -input samples is user for solving cold start problem for the model.\n",
    "        -test samples is used to evaluate the model.\n",
    "    '''\n",
    "    user_ratings_input_samples, user_ratings_true_samples = test_spark_df.where(test_spark_df.user_id==user_id).randomSplit(split_ratio)\n",
    "    return user_ratings_input_samples, user_ratings_true_samples\n",
    "\n",
    "user_ratings_input_samples, user_ratings_true_samples = split_test_to_input_true(test_spark_df, test_users_id[0])\n",
    "\n",
    "user_ratings_input_samples.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cb1d6f7-cf5d-4ccb-946e-4314ae70a919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+--------------------+\n",
      "|user_id|item_id|rating|timestamp|               title|\n",
      "+-------+-------+------+---------+--------------------+\n",
      "|    359|     50|     5|886453271|    Star Wars (1977)|\n",
      "|    359|    117|     4|886453305|    Rock, The (1996)|\n",
      "|    359|    118|     3|886453402|      Twister (1996)|\n",
      "|    359|    181|     5|886453305|Return of the Jed...|\n",
      "|    359|    246|     3|886453214|  Chasing Amy (1997)|\n",
      "|    359|    268|     4|886453490|  Chasing Amy (1997)|\n",
      "|    359|    323|     3|886453431| Dante's Peak (1997)|\n",
      "|    359|    546|     3|886453373| Broken Arrow (1996)|\n",
      "|    359|    250|     4|886453354|Fifth Element, Th...|\n",
      "|    359|    286|     5|886453161|English Patient, ...|\n",
      "|    359|    408|     5|886453239|Close Shave, A (1...|\n",
      "|    359|    455|     4|886453305|Jackie Chan's Fir...|\n",
      "|    359|    751|     4|886453467|Tomorrow Never Di...|\n",
      "|    359|    930|     4|886453402|Chain Reaction (1...|\n",
      "|    359|     24|     3|886453354|Rumble in the Bro...|\n",
      "|    359|    472|     4|886453402|  Dragonheart (1996)|\n",
      "|    359|    831|     3|886453402|Escape from L.A. ...|\n",
      "|    359|    270|     4|886453467|      Gattaca (1997)|\n",
      "|    359|    313|     5|886453450|      Titanic (1997)|\n",
      "+-------+-------+------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_ratings_true_samples.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5343cb1f-8a82-435c-8e14-f24412d554bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_spark_df (760, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_users_ratings_input_samples (151, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 135:==========================================>            (31 + 4) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_users_ratings_true_samples (609, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_users_ratings_input_samples = None # Create a test data samples for solving cold start problem. This can also be done by asking new users to rate the movies/items which they have already seen/used.\n",
    "test_users_ratings_true_samples = None # True ratings from users for evaluation of recommendation model\n",
    "\n",
    "for user_id in test_users_id:\n",
    "    user_ratings_input_samples, user_ratings_true_samples = split_test_to_input_true(test_spark_df, user_id)\n",
    "\n",
    "    if test_users_ratings_input_samples==None: # Initialising the test data input samples\n",
    "        test_users_ratings_input_samples, test_users_ratings_true_samples = user_ratings_input_samples, user_ratings_true_samples\n",
    "    else:\n",
    "        test_users_ratings_input_samples = test_users_ratings_input_samples.union(user_ratings_input_samples)\n",
    "        test_users_ratings_true_samples = test_users_ratings_true_samples.union(user_ratings_true_samples)\n",
    "\n",
    "print(\"Shape of test_spark_df\",(test_spark_df.count(), len(test_spark_df.columns)))\n",
    "print(\"Shape of test_users_ratings_input_samples\",(test_users_ratings_input_samples.count(), len(test_users_ratings_input_samples.columns)))\n",
    "print(\"Shape of test_users_ratings_true_samples\",(test_users_ratings_true_samples.count(), len(test_users_ratings_true_samples.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc05d16-d50a-49c4-84d5-58e210e256f8",
   "metadata": {},
   "source": [
    "### Prediction of ratings for new users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "722cc8a3-de5b-46b9-8c0f-3bf10a88aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def new_user_recs(new_user_rating_samples, user_ratings_true_samples, rating_df):\n",
    "    '''Function to recommending new user with movies/items utilizing ALS alhorithm for implementing colaborative filtering\n",
    "\n",
    "        Prameters:\n",
    "            new_user_rating_samples (spark dataframe): Dataframe consisting of new user rating data to avoid cold start issue.\n",
    "            user_ratings_true_samples (spark dataframe): Dataframe consisting of item ids for making predictions of ratings for model.\n",
    "            rating_df (spark dataframe): Dataframe for consisting of all the users rating data for training the model.\n",
    "        Returns:\n",
    "            recommendations (spark dataframe): Dataframe consisting of all the predictions of ratings for the test data\n",
    "    '''\n",
    "    \n",
    "    user_id = new_user_rating_samples.user_id\n",
    "    \n",
    "    # combine the new ratings df with the rating_df\n",
    "    movie_ratings_combined = rating_df.union(new_user_rating_samples)\n",
    "    \n",
    "    # create an ALS model and fit it\n",
    "    als = ALS(maxIter=10, rank=50, regParam=0.15, userCol='user_id', itemCol='item_id', ratingCol='rating', coldStartStrategy='drop')\n",
    "    model = als.fit(movie_ratings_combined)\n",
    "    \n",
    "    # make recommendations for the evaluation test samples of the users\n",
    "    recommendations = model.transform(user_ratings_true_samples)\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "baece55f-b9f9-4621-abb9-f7dddf9d4951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_users_ratings_true_samples (609, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 301:>(32 + 4) / 40][Stage 325:> (0 + 0) / 10][Stage 326:> (0 + 0) / 10]0]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+--------------------+----------+\n",
      "|user_id|item_id|rating|timestamp|               title|prediction|\n",
      "+-------+-------+------+---------+--------------------+----------+\n",
      "|    359|      1|     4|886453214|    Toy Story (1995)| 4.1119237|\n",
      "|    359|     50|     5|886453271|    Star Wars (1977)| 4.6748705|\n",
      "|    359|    117|     4|886453305|    Rock, The (1996)|   3.94903|\n",
      "|    359|    118|     3|886453402|      Twister (1996)| 3.4114106|\n",
      "|    359|    181|     5|886453305|Return of the Jed...| 4.3436007|\n",
      "|    359|    246|     3|886453214|  Chasing Amy (1997)| 4.0255575|\n",
      "|    359|    323|     3|886453431| Dante's Peak (1997)| 3.1419852|\n",
      "|    359|    405|     3|886453354|Mission: Impossib...|  3.534722|\n",
      "|    359|    250|     4|886453354|Fifth Element, Th...| 3.7331085|\n",
      "|    359|    286|     5|886453161|English Patient, ...| 3.7667239|\n",
      "|    359|    298|     5|886453354|     Face/Off (1997)| 3.9854944|\n",
      "|    359|    408|     5|886453239|Close Shave, A (1...| 4.7247744|\n",
      "|    359|    455|     4|886453305|Jackie Chan's Fir...| 3.5342276|\n",
      "|    359|    930|     4|886453402|Chain Reaction (1...| 2.9272242|\n",
      "|    359|     24|     3|886453354|Rumble in the Bro...|   3.66841|\n",
      "|    359|    295|     3|886453325|    Breakdown (1997)| 3.4833844|\n",
      "|    359|    831|     3|886453402|Escape from L.A. ...| 2.6460466|\n",
      "|    359|    270|     4|886453467|      Gattaca (1997)|  3.890171|\n",
      "|    359|    313|     5|886453450|      Titanic (1997)|  4.502071|\n",
      "|    162|     25|     4|877635573|Birdcage, The (1996)| 3.3054323|\n",
      "+-------+-------+------+---------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "user_predicted_recoms = new_user_recs(test_users_ratings_input_samples, test_users_ratings_true_samples ,spark_df)\n",
    "print(\"Shape of test_users_ratings_true_samples\",(user_predicted_recoms.count(), len(user_predicted_recoms.columns)))\n",
    "user_predicted_recoms.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf8e545-5797-4c85-809e-885ad61f6d81",
   "metadata": {},
   "source": [
    "### Evaluation of the recommendations using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fecb12b-733c-4761-a1ac-75129f1359a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 356:>(33 + 4) / 40][Stage 380:> (0 + 0) / 10][Stage 381:> (0 + 0) / 10]0]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.8293336492994183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluate_recommendation(user_predicted_recoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c6efc6-5179-4a7c-b6bf-66c18ac2554d",
   "metadata": {},
   "source": [
    "## Movie Recommendations of test users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bd24bea-ff2f-4dfa-a831-e6efee77f8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for User 359\n",
      "\t Close Shave, A (1995)\n",
      "\t Star Wars (1977)\n",
      "\t Titanic (1997)\n",
      "\t Return of the Jedi (1983)\n",
      "\t Toy Story (1995)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for User 162\n",
      "\t Star Wars (1977)\n",
      "\t Fugitive, The (1993)\n",
      "\t Die xue shuang xiong (Killer, The) (1989)\n",
      "\t Return of the Jedi (1983)\n",
      "\t Apollo 13 (1995)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for User 62\n",
      "\t Wallace & Gromit: The Best of Aardman Animation (1996)\n",
      "\t Casablanca (1942)\n",
      "\t Usual Suspects, The (1995)\n",
      "\t Star Wars (1977)\n",
      "\t Shawshank Redemption, The (1994)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for User 243\n",
      "\t Schindler's List (1993)\n",
      "\t Secrets & Lies (1996)\n",
      "\t Lawrence of Arabia (1962)\n",
      "\t Persuasion (1995)\n",
      "\t Godfather, The (1972)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for User 767\n",
      "\t Casablanca (1942)\n",
      "\t Manchurian Candidate, The (1962)\n",
      "\t Fargo (1996)\n",
      "\t Godfather: Part II, The (1974)\n",
      "\t Cinema Paradiso (1988)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for User 421\n",
      "\t Usual Suspects, The (1995)\n",
      "\t Raiders of the Lost Ark (1981)\n",
      "\t Godfather, The (1972)\n",
      "\t Silence of the Lambs, The (1991)\n",
      "\t Empire Strikes Back, The (1980)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for User 841\n",
      "\t Titanic (1997)\n",
      "\t Good Will Hunting (1997)\n",
      "\t As Good As It Gets (1997)\n",
      "\t Ayn Rand: A Sense of Life (1997)\n",
      "\t Apt Pupil (1998)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for User 546\n",
      "\t Return of the Jedi (1983)\n",
      "\t Wag the Dog (1997)\n",
      "\t Star Trek: First Contact (1996)\n",
      "\t Twelve Monkeys (1995)\n",
      "\t Titanic (1997)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for User 358\n",
      "\t Kaspar Hauser (1993)\n",
      "\t Stalker (1979)\n",
      "\t Three Colors: Red (1994)\n",
      "\t 8 1/2 (1963)\n",
      "\t Double vie de Véronique, La (Double Life of Veronique, The) (1991)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for User 847\n",
      "\t Sum of Us, The (1994)\n",
      "\t Star Wars (1977)\n",
      "\t Picture Bride (1995)\n",
      "\t Empire Strikes Back, The (1980)\n",
      "\t Contact (1997)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for user_id in test_users_id:\n",
    "    single_user_predicted_recoms = user_predicted_recoms.where(user_predicted_recoms.user_id==user_id)\n",
    "    singel_user_recomm_movies  = single_user_predicted_recoms.sort('prediction',ascending=False).select('title').rdd.flatMap(lambda x: x).take(5)\n",
    "    print(f'Recommendation for User {user_id}')\n",
    "    for title in singel_user_recomm_movies:\n",
    "        print('\\t', title)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d926e890-c5ee-4251-925f-f0372e52598f",
   "metadata": {},
   "source": [
    "# Object Oriented Implementation:\n",
    "The Object Oriented Programming implementation of the above code is as follows:\n",
    "\n",
    "There are 2 Classes that are implementer:\n",
    "\n",
    "* **ColaborativeFilteringALS** class - Implementation of Colaborative filtering recommendation system using ALS algorithm in pyspark.\n",
    "* **User** class - Dummy class for replicating users in any system utilising recommendation feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38fb45f9-5a7b-4123-a658-e9fe14ec7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class user():\n",
    "    \"\"\"User class to reresent users in a sustem that utilises recommendation system\"\"\"\n",
    "    def __init__(self, user_id, user_input_samples=None):\n",
    "        self.user_id = user_id\n",
    "        self.user_input_samples = user_input_samples\n",
    "        self.predicted_ratings = None\n",
    "\n",
    "    def set_predicted_ratings(self,predicted_ratings_df):\n",
    "        \"\"\"Method to set the predcited rating given by the recommender class\n",
    "            Parameters:\n",
    "                predicted_ratings_df (spark dataframe): Dataframe consisting of user sample item/movie rating data for solving cold start issue.\n",
    "        \"\"\"\n",
    "        self.predicted_ratings = predicted_ratings_df\n",
    "\n",
    "    def get_recommendations(self, n=5, title_col='title'):\n",
    "        \"\"\"Method for getting the n number of top recommended items given by the recommendation system.\n",
    "            This methods needs to be called after predictions of ratings is done my the recommender system.\n",
    "            Returns:\n",
    "                recommendations (list(str)): list of top n number of recommended items with first item with highest ratings.\n",
    "        \"\"\"\n",
    "        reccommendations = None\n",
    "        if self.predicted_ratings:\n",
    "            reccommendations = self.predicted_ratings.select(title_col).rdd.flatMap(lambda x:x).take(n)\n",
    "        return reccommendations\n",
    "\n",
    "class ColaborativeFilteringALS():\n",
    "    def __init__(self, spark_session, pandas_dataframe,  user_col='user_id', item_col='item_id', rating_col='rating', title_col='title'):\n",
    "        \"\"\"\n",
    "        Class implementation of colaborative filtering using ALS algorithm with pyspark.\n",
    "\n",
    "        Parameters:\n",
    "            spark_session (spark session): created spark session to use.\n",
    "            pandas_dataframe (pandas dataframe): Pandas dataframe containing the user ids, item ids and their ratings.\n",
    "            userCol (str): default='user_id', Specify column in dataframe which contains user ids,\n",
    "            itemCol (str): default='item_id', Specify column in dataframe which contains item ids,\n",
    "            ratingCol (str): default='rating', Specify column in dataframe which contains user ratings,\n",
    "        \"\"\"\n",
    "        self.spark_session = spark_session\n",
    "        self.pandas_dataframe = pandas_dataframe\n",
    "        self._userCol = user_col\n",
    "        self._itemCol = item_col\n",
    "        self._ratingCol = rating_col\n",
    "        self._titleCol = title_col\n",
    "        self.spark_dataframe = self.spark_session.createDataFrame(self.pandas_dataframe.iloc[:,:])\n",
    "\n",
    "    def show_dataframe(self, spark_df=None):\n",
    "        \"\"\"Shows the spark dataframe of the user rating data provided.\n",
    "            Parameters:\n",
    "                spark_df (spark dataframe): Dataframe that needs to be displayed.\n",
    "        \"\"\"\n",
    "        if spark_df==None:\n",
    "            spark_df = self.spark_dataframe\n",
    "        self._print_df_diamension(spark_df)\n",
    "        spark_df.show()\n",
    "\n",
    "    def _print_df_diamension(self, spark_df):\n",
    "        \"\"\"Prints the diamentions of the spark dataframe.\"\"\"\n",
    "        print(f\"Shape: \",(spark_df.count(), len(spark_df.columns)))\n",
    "\n",
    "    def sample_test_users(self, n_users=5):\n",
    "        \"\"\"Create a list of n number or sample test users for testing/evaluation\n",
    "        Parameters:\n",
    "            n_users (int): Default=5, Number of users for tesing/evaluating the recommender model\n",
    "\n",
    "        Returns:\n",
    "            test_users_id (list(str)): List of test user ids that are randomly selected.\n",
    "        \"\"\"\n",
    "        test_users_id = random.sample(sorted(self.pandas_dataframe['user_id'].unique()), n_users) # Selected random 10 users for testing\n",
    "        return test_users_id\n",
    "\n",
    "    def _split_test_to_input_true(self, test_spark_df, user_id, split_ratio=(0.2,0.8)):\n",
    "        '''Here we take the random samples for each user and split them in input samples and test samples, \n",
    "            -input samples is user for solving cold start problem for the model.\n",
    "            -test samples is used to evaluate the model.\n",
    "        '''\n",
    "        user_ratings_input_samples, user_ratings_true_samples = test_spark_df.where(test_spark_df.user_id==user_id).randomSplit(split_ratio)\n",
    "        # user_ratings_input_samples = test_spark_df.where(test_spark_df.user_id==user_id).limit(5)\n",
    "        # user_ratings_true_samples = test_spark_df.where(~test_spark_df.item_id.isin(user_ratings_input_samples.select('item_id').rdd.flatMap(lambda x: x).collect()))\n",
    "        return user_ratings_input_samples, user_ratings_true_samples\n",
    "    \n",
    "    def train_test_split(self, test_users_id):\n",
    "        \"\"\"Method to create a train test spplit by users\n",
    "        Parameters:\n",
    "            test_users_id (list(str)): List of test user ids that are selected for testing/evaluation.\n",
    "\n",
    "        Returns:\n",
    "            modified_train_spark_df (spark dataframe): All data with test user input sample data for solving cold start problem\n",
    "            test_spark_df (spark dataframe): Test user data selected from all data\n",
    "            \n",
    "        \"\"\"\n",
    "        train_spark_df = self.spark_dataframe.filter(~self.spark_dataframe.user_id.isin(test_users_id)) #Filtering the other users for creating training data\n",
    "        test_spark_df = self.spark_dataframe.filter(self.spark_dataframe.user_id.isin(test_users_id)) #Filtering the test users for creating test data\n",
    "\n",
    "        \n",
    "        print(f\"Full Dataset {(self.spark_dataframe.count(), len(self.spark_dataframe.columns))}\")\n",
    "        print(\"Shape of initial train test split by test user ids:\", test_users_id)\n",
    "        print(f\"\\t Train Dataset {(train_spark_df.count(), len(train_spark_df.columns))}\")\n",
    "        print(f\"\\t Test Dataset {(test_spark_df.count(), len(test_spark_df.columns))}\")\n",
    "        print('\\n Modifying train and test dataset to solve cold start problem... \\n')\n",
    "        \n",
    "        modified_train_spark_df = train_spark_df # Training spark dataframe with input samples for solving cold start issue\n",
    "        modified_test_spark_df = None # Test spark_dataframe without input sample taken for training\n",
    "        for user_id in test_users_id:\n",
    "            # Create a test data samples for solving cold start problem. This can also be done by asking new users to rate the movies/items which they have already seen/used.\n",
    "            # True ratings from users for evaluation of recommendation model\n",
    "            user_ratings_input_samples, user_ratings_true_samples = self._split_test_to_input_true(test_spark_df, user_id)\n",
    "\n",
    "            if modified_test_spark_df==None: # Initialising the test data input samples\n",
    "                modified_test_spark_df = user_ratings_true_samples\n",
    "                \n",
    "            modified_train_spark_df = modified_train_spark_df.union(user_ratings_input_samples)\n",
    "            modified_test_spark_df = modified_test_spark_df.union(user_ratings_true_samples)\n",
    "\n",
    "        print(\"Shape of modified train and test datasets:\")\n",
    "        print(f\"\\t Modified Train Dataset {(modified_train_spark_df.count(), len(modified_train_spark_df.columns))}\")\n",
    "        print(f\"\\t Modified Test Dataset {(modified_test_spark_df.count(), len(modified_test_spark_df.columns))}\")\n",
    "        \n",
    "        return modified_train_spark_df, modified_test_spark_df\n",
    "\n",
    "    def model_fit(self, train_spark_df):\n",
    "        # create an ALS model and fit it\n",
    "        als = ALS(maxIter=10, rank=50, regParam=0.15, userCol=self._userCol, itemCol=self._itemCol, ratingCol=self._ratingCol, coldStartStrategy='drop')\n",
    "        model = als.fit(train_spark_df)\n",
    "        return model\n",
    "\n",
    "    def model_transform(self, model, test_spark_df):\n",
    "        # make recommendations for the evaluation test samples of the users\n",
    "        recommendations = model.transform(test_spark_df)\n",
    "        return recommendations\n",
    "\n",
    "    def model_fit_transform(self, modified_train_spark_df, modified_test_spark_df):\n",
    "        '''Function to recommending new user with movies/items utilizing ALS alhorithm for implementing colaborative filtering\n",
    "    \n",
    "            Prameters:\n",
    "                modified_train_spark_df (spark dataframe): Dataframe consisting of all the user rating data and new user rating data to avoid cold start issue.\n",
    "                modified_test_spark_df (spark dataframe): Dataframe consisting of testing data with item ids for making predictions of ratings for model.\n",
    "            Returns:\n",
    "                recommendations (spark dataframe): Dataframe consisting of all the predictions of ratings for the test data\n",
    "        '''\n",
    "        \n",
    "        # train model\n",
    "        model = self.model_fit(modified_train_spark_df)\n",
    "        \n",
    "        # make predictions\n",
    "        recommendations = self.model_transform(model, modified_test_spark_df)\n",
    "    \n",
    "        return recommendations\n",
    "\n",
    "    def create_all_item_df(self):\n",
    "        \"\"\"Creates a spark dataframe containing all the item ids.\"\"\"\n",
    "        return spark_df.dropDuplicates([self._itemCol]).select([self._itemCol, self._titleCol])\n",
    "        \n",
    "    def new_user_recommendations(self, new_user):\n",
    "        \"\"\"Predicts ratings for item for the new user with input samples. Returns the recommendations in ascending order-Top rated items are at the top.\n",
    "\n",
    "        Parameters:\n",
    "            new_user (obj): New user object containing user_id and sample of rating from user for items for solving cold start issue\n",
    "\n",
    "        Returns:\n",
    "            recommendation (spark dataframe): Dataframe containing predicted ratings for each items sorted in order of highest ratings first.\n",
    "        \"\"\"\n",
    "        \n",
    "        # user_id = user_data_samples.select(self._userCol).rdd.flatMap(lambda x:x).take(1)[0] #Get user id\n",
    "        \n",
    "        # combine the new ratings df with the rating_df\n",
    "        # user_input_samples = new_user.user_input_samples.withColumn(self._userCol, lit(new_user.user_id))\n",
    "        movie_ratings_combined = self.spark_dataframe.union(new_user.user_input_samples)\n",
    "        # train model\n",
    "        model = self.model_fit(movie_ratings_combined)\n",
    "\n",
    "        # Get all the item ids for making predictions\n",
    "        all_item_ids = self.create_all_item_df()\n",
    "        all_item_ids = all_item_ids.withColumn(self._userCol, lit(new_user.user_id))\n",
    "\n",
    "        # make predictions\n",
    "        recommendations = self.model_transform(model, all_item_ids)\n",
    "        recommendations = recommendations.sort('prediction', ascending=False)\n",
    "        \n",
    "        return recommendations\n",
    "        \n",
    "    def evaluate_recommendation(self, recommendation_df):\n",
    "        \"\"\"Function for evaluating the recommendation predictions form the model. \n",
    "            Evaluation metrics calculated-\n",
    "                1.Root mean squared error of actual user ratings and predicted user ratings.\n",
    "                \n",
    "            Parameters:\n",
    "                recommendation_df(spark dataframe): Dataframe consisting of user rating and predicted ratings for each item/movie.\n",
    "            Return: None\n",
    "        \"\"\"\n",
    "        evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=self._ratingCol,predictionCol=\"prediction\")\n",
    "        rmse = evaluator.evaluate(recommendation_df)\n",
    "        print(\"Root-mean-square error = \" + str(rmse))\n",
    "    \n",
    "    @property\n",
    "    def number_of_users(self): \n",
    "        print('Number of users:', self.pandas_dataframe[self._userCol].nunique())\n",
    "\n",
    "    def users_rating_counts(self, spark_df=None, n=10):\n",
    "        if spark_df==None:\n",
    "            spark_df = self.spark_dataframe\n",
    "        spark_df.groupBy(self._userCol).count().show(n) # Count of movies each user rated\n",
    "            \n",
    "    @property\n",
    "    def unique_users(self):\n",
    "        print('Unique users in dataframe:')\n",
    "        print(self.pandas_dataframe[self._userCol].unique()) # Unique users in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86776225-1c2d-4b48-bdd7-f79dd795e38e",
   "metadata": {},
   "source": [
    "### Initialising the classes and understanding the implemented methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adcaf14b-0dc9-408e-9899-05db533b33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = ColaborativeFilteringALS(spark, df) # Initialise an object of ColaborativeFilteringALS class by passing in spark session object and pandas dataframe consisting of the rating data by all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1f49b09-38af-4832-bd6d-2a2c82e630f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (100003, 5)\n",
      "+-------+-------+------+---------+----------------+\n",
      "|user_id|item_id|rating|timestamp|           title|\n",
      "+-------+-------+------+---------+----------------+\n",
      "|      0|     50|     5|881250949|Star Wars (1977)|\n",
      "|    290|     50|     5|880473582|Star Wars (1977)|\n",
      "|     79|     50|     4|891271545|Star Wars (1977)|\n",
      "|      2|     50|     5|888552084|Star Wars (1977)|\n",
      "|      8|     50|     5|879362124|Star Wars (1977)|\n",
      "|    274|     50|     5|878944679|Star Wars (1977)|\n",
      "|    227|     50|     4|879035347|Star Wars (1977)|\n",
      "|     99|     50|     5|885679998|Star Wars (1977)|\n",
      "|    305|     50|     5|886321799|Star Wars (1977)|\n",
      "|    108|     50|     4|879879739|Star Wars (1977)|\n",
      "|     63|     50|     4|875747292|Star Wars (1977)|\n",
      "|    234|     50|     4|892079237|Star Wars (1977)|\n",
      "|     97|     50|     5|884239471|Star Wars (1977)|\n",
      "|    117|     50|     5|880126022|Star Wars (1977)|\n",
      "|     70|     50|     4|884064188|Star Wars (1977)|\n",
      "|    318|     50|     2|884495696|Star Wars (1977)|\n",
      "|    145|     50|     5|885557660|Star Wars (1977)|\n",
      "|    124|     50|     3|890287508|Star Wars (1977)|\n",
      "|    253|     50|     4|891628518|Star Wars (1977)|\n",
      "|    271|     50|     5|885848640|Star Wars (1977)|\n",
      "+-------+-------+------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cf.show_dataframe() # Viewing all the users rating data for understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b68f4129-6bd4-43c6-9be6-fbffb9a3944b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 944\n"
     ]
    }
   ],
   "source": [
    "cf.number_of_users # Checking the number of unique users in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c2e75f0-5447-4079-acc8-de859d68acc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users in dataframe:\n",
      "[  0 290  79   2   8 274 227  99 305 108  63 234  97 117  70 318 145 124\n",
      " 253 271 254 326 213  80 322  28 267 130 262 230 316 327 299 144 162  48\n",
      " 141 251 297 137 154 257 269 123  94 330 368  77 321 381  43 286 247  68\n",
      " 150 214 210 158 279 288 280  25 102 209 103 398 379 409 386 407 101 201\n",
      " 203 283 128 200  58  54 311  96   4 401  71  59 176 393  14  12 432 378\n",
      " 245 115 406 444 160  23 433 125 320 438 461 250 437 119  27 275 389 445\n",
      " 270 422 465 467 157 276  65  10 435 458 478   6 192 387 405 287  64 369\n",
      " 272 394 334 346 352 177 153  62 148 325  15 456 371 506 360 509 533 454\n",
      " 340 239 221 215 194  45   5 479 303 494 504 347 161 313 113 453 540 402\n",
      "  66 523 536 527 277 549 551 530 339  49 539 581 484 294 592 463 217  87\n",
      "  91 417 569 498 293  46 495 385  69 248 399 528 382 151 416  37 345 470\n",
      " 411 244 350 623 516 430 493 624 517 370 268 324 638 563 178 618  26 642\n",
      " 653 354  60 644 496 184 650  30 457 343 552 600 263 662 471 602 363 541\n",
      " 481 421 597 503 550 521  89 629 189 672 182 622 323 582 654 682 426 619\n",
      " 235 608 526 698 660   1 308 637 575 694 634 474 705 169 310 499 719 594\n",
      " 505 490 488 557  72 537 296 721 704 175 655 730 482  21 429 676 736 233\n",
      " 758 710 674 413 500 757 116  13 593 708 373  55 424 395 374 663 573 524\n",
      " 706 691 711 174 475 104 751 576 794 700 236 610 513 678  53 703 487 367\n",
      " 768 714  42 659 630 301 799 198 797 564 658 761 132 231 216 826 746 835\n",
      " 862 791 292  85 727 825 392 760 419 337 864 748 701 744 643 753  92 833\n",
      "  51 747 265 717 397 851 295 669 880 514 883 561 830 632 664 844  56 641\n",
      " 789 891 507 697 742 881 466 716 871  44 831 931 391 846 468  82 934 815\n",
      " 256 902 298 450 665 917 869 776 919 689 567 512 878 834 867 796   9 868\n",
      " 480 344 329 806 671 649 249 380 621 185 455 606 699 127 483 839 790 312\n",
      " 121 916 679 668 922 892 232 246 436 222 452 854 895 548 897  57 852 546\n",
      " 709  22 765 936 805 766 770 580 613 882 875 459 291 712 899 562 555 889\n",
      " 595 896 586 684 763 601 942 741 756 890 633 840 359 735 447 843 850 188\n",
      " 745 764 738 680 553 603 554 870 804 328 773 197  18  32 566 645  20 577\n",
      " 486 823 759 579 879   7 940 793 938 625 910 894 620 901 798 332 781 908\n",
      " 848 885 686 795 807 183 425 786 937 887 666 588 596 907 933 464  95  41\n",
      " 545 109 715 913 403 723 538  83 307 472 542 924 929 930 560 535 923 800\n",
      " 336 508 693 661 361 921 120 832 943 782 785 893 584 847 838 774 771 497\n",
      " 779 648 734 749 886 739 903 780 204 202 225 412  76 627 591  16 767 849\n",
      " 118 912 556 259 932 442 707 492 911 928 114 788 207 331 167 338  38 342\n",
      " 138 152 522 605  90 683 918 731 196 226 306  34  35 199 173 309 111 439\n",
      " 355 131 451 532 181 639 520 617  86 651 460 129  40 740 733 568 673 205\n",
      " 440 139 628 473 695 206 863 866 803 240 898 485 574 724 428 861 408 195\n",
      " 743 675 845 720 186 191 190  31 100 315  88 282 208 112 126 319  47 146\n",
      " 171 107 229 427  29 420 241 383 418 179 362 149 285 489 390 140 446 404\n",
      " 423   3 375 570 105 414 531 515 685 543 384 431 762 134 640  52  74 364\n",
      " 818 284 853 755 828 388 808 448 787 713 775 865 696 809 802 615 547 827\n",
      " 752 656 920 657 819 905 801 626 860 278 688 587 926 877 784 841 842  39\n",
      " 836 820 616 915 772 611 544 812 147 874 635 314 224  11 690 166 156 133\n",
      " 511 142 631 646 353 702 783 578 519 462 729  73 237 469 607 900 737 670\n",
      "  84 218 135 583 559 778 193 159 264 110 914 904 476 477 106 187 243 212\n",
      " 667 585 855 122 829 565 884 449 909 211 168 300  78 501 223 647 726 525\n",
      " 652 935 238 859 927 941 692 136 939 718 219 599 590  93 357  81 165 289\n",
      " 365 518 636 396 255 164 180 677 572 769 837  75 817  17 376 534 434 821\n",
      " 872 888 304  24 571 348 349 612 722 754 792  67 242 252 441 614 777 609\n",
      " 822 728 906 163 604 366 377 814 372  50 333 228 925  98 172 261  61 400\n",
      " 281 170 681 811 824 810 273 750 589 813 351 732 857 443 155 529 856 858\n",
      "  19 258 220 816 491 725 558 266 415 260 302 317 335 510 356 143 341  36\n",
      " 687 502 876  33 358 410 598 873]\n"
     ]
    }
   ],
   "source": [
    "cf.unique_users # Checking all the user ids in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a8bbca-fd98-464a-8c00-b3551e7df7c8",
   "metadata": {},
   "source": [
    "### Testing and Evaluation\n",
    "\n",
    "Testing the recommender system by sampling 'n' number of users randomply and evaluating it with the evaluation meathod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac6c1af2-062b-4203-ab32-5ac9b9b2acb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ids selected for testing/evaluation of the model: [888, 846, 543, 392, 212, 852, 668, 402, 674, 192]\n"
     ]
    }
   ],
   "source": [
    "test_users_id = cf.sample_test_users(10) # Making and list of 10 user ids selected randomly for testing\n",
    "print('User ids selected for testing/evaluation of the model:',test_users_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de677f1c-9a44-4ac7-a9c3-49df1afb92f0",
   "metadata": {},
   "source": [
    "Splitting the data into train and test data for cross validation.\n",
    "\n",
    "*Note*: Here the train dataset contains some sample input data from each of the test users for solving cold start issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6053d7a-83f8-4ec7-b27a-03ca3e78f380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset (100003, 5)\n",
      "Shape of initial train test split by test user ids: [888, 846, 543, 392, 212, 852, 668, 402, 674, 192]\n",
      "\t Train Dataset (99006, 5)\n",
      "\t Test Dataset (997, 5)\n",
      "\n",
      " Modifying train and test dataset to solve cold start problem... \n",
      "\n",
      "Shape of modified train and test datasets:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Modified Train Dataset (99202, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1446:====================================================> (43 + 1) / 44]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Modified Test Dataset (817, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df, test_df = cf.train_test_split(test_users_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86b14acb-ee4b-422f-aba3-2b2fe252845b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1449:============================================>         (36 + 4) / 44]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (99202, 5)\n",
      "+-------+-------+------+---------+----------------+\n",
      "|user_id|item_id|rating|timestamp|           title|\n",
      "+-------+-------+------+---------+----------------+\n",
      "|      0|     50|     5|881250949|Star Wars (1977)|\n",
      "|    290|     50|     5|880473582|Star Wars (1977)|\n",
      "|     79|     50|     4|891271545|Star Wars (1977)|\n",
      "|      2|     50|     5|888552084|Star Wars (1977)|\n",
      "|      8|     50|     5|879362124|Star Wars (1977)|\n",
      "|    274|     50|     5|878944679|Star Wars (1977)|\n",
      "|    227|     50|     4|879035347|Star Wars (1977)|\n",
      "|     99|     50|     5|885679998|Star Wars (1977)|\n",
      "|    305|     50|     5|886321799|Star Wars (1977)|\n",
      "|    108|     50|     4|879879739|Star Wars (1977)|\n",
      "|     63|     50|     4|875747292|Star Wars (1977)|\n",
      "|    234|     50|     4|892079237|Star Wars (1977)|\n",
      "|     97|     50|     5|884239471|Star Wars (1977)|\n",
      "|    117|     50|     5|880126022|Star Wars (1977)|\n",
      "|     70|     50|     4|884064188|Star Wars (1977)|\n",
      "|    318|     50|     2|884495696|Star Wars (1977)|\n",
      "|    145|     50|     5|885557660|Star Wars (1977)|\n",
      "|    124|     50|     3|890287508|Star Wars (1977)|\n",
      "|    253|     50|     4|891628518|Star Wars (1977)|\n",
      "|    271|     50|     5|885848640|Star Wars (1977)|\n",
      "+-------+-------+------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cf.show_dataframe(train_df) # Checking the train dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31e55fd8-7a9a-498a-bd8f-fcc61fac772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (817, 5)\n",
      "+-------+-------+------+---------+--------------------+\n",
      "|user_id|item_id|rating|timestamp|               title|\n",
      "+-------+-------+------+---------+--------------------+\n",
      "|    888|    100|     4|879365004|        Fargo (1996)|\n",
      "|    888|    111|     4|879365072|Truth About Cats ...|\n",
      "|    888|    237|     5|879365449|Jerry Maguire (1996)|\n",
      "|    888|    274|     4|879365497|      Sabrina (1995)|\n",
      "|    888|     69|     4|879365104| Forrest Gump (1994)|\n",
      "|    888|    137|     4|879365104|    Big Night (1996)|\n",
      "|    888|    153|     4|879365154|Fish Called Wanda...|\n",
      "|    888|    191|     5|879365004|      Amadeus (1984)|\n",
      "|    888|    202|     4|879365072|Groundhog Day (1993)|\n",
      "|    888|    280|     3|879365475|Up Close and Pers...|\n",
      "|    888|    286|     5|879364981|English Patient, ...|\n",
      "|    888|    631|     4|879365224|Crying Game, The ...|\n",
      "|    888|    269|     5|879364981|Full Monty, The (...|\n",
      "|    888|    792|     5|879365054|Bullets Over Broa...|\n",
      "|    888|    869|     4|879365086|Fools Rush In (1997)|\n",
      "|    888|    535|     4|879365497|Addicted to Love ...|\n",
      "|    888|    100|     4|879365004|        Fargo (1996)|\n",
      "|    888|    111|     4|879365072|Truth About Cats ...|\n",
      "|    888|    237|     5|879365449|Jerry Maguire (1996)|\n",
      "|    888|    274|     4|879365497|      Sabrina (1995)|\n",
      "+-------+-------+------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cf.show_dataframe(test_df) # Checking the test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc1987fe-b02c-4c7e-83b1-b9a96fd1a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1459:=============================================>        (37 + 4) / 44]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|user_id|count|\n",
      "+-------+-----+\n",
      "|    888|   32|\n",
      "|    846|  331|\n",
      "|    543|  155|\n",
      "|    392|   88|\n",
      "|    212|   21|\n",
      "|    852|   34|\n",
      "|    668|   42|\n",
      "|    402|   56|\n",
      "|    674|   31|\n",
      "|    192|   27|\n",
      "+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cf.users_rating_counts(spark_df=test_df) # Checking the count of each items user rated in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d924a13-5c51-4180-9920-ce97e73f5515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1516:(42 + 2) / 44][Stage 1540:>(2 + 2) / 10][Stage 1541:>(0 + 0) / 10]  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+--------------------+----------+\n",
      "|user_id|item_id|rating|timestamp|               title|prediction|\n",
      "+-------+-------+------+---------+--------------------+----------+\n",
      "|    392|    463|     3|891038946|Secret of Roan In...| 3.7258215|\n",
      "|    402|    471|     4|876267041|Courage Under Fir...|  3.372477|\n",
      "|    543|    471|     3|875657863|Courage Under Fir...| 3.4017196|\n",
      "|    543|    463|     3|874864034|Secret of Roan In...| 3.6758442|\n",
      "|    846|    463|     5|883948222|Secret of Roan In...| 3.7333486|\n",
      "|    846|    623|     1|883950889|Angels in the Out...|  2.611689|\n",
      "|    846|    540|     2|883950711|  Money Train (1995)| 2.4158823|\n",
      "|    392|   1143|     4|891038158|   Hard Eight (1996)| 4.1406717|\n",
      "|    543|    516|     4|876896210|   Local Hero (1983)|  3.861484|\n",
      "|    846|    516|     4|883948457|   Local Hero (1983)|   3.87139|\n",
      "|    846|     31|     4|883948571| Crimson Tide (1995)| 3.6149774|\n",
      "|    192|   1265|     3|881366585|    Star Maps (1997)| 2.2213469|\n",
      "|    402|    137|     4|876266701|    Big Night (1996)|  4.342444|\n",
      "|    543|     85|     2|877547580|     Ref, The (1994)|  2.751126|\n",
      "|    668|    137|     3|881605093|    Big Night (1996)|  3.670492|\n",
      "|    846|    580|     5|883949335|Englishman Who We...| 3.2921085|\n",
      "|    888|    137|     4|879365104|    Big Night (1996)| 4.3304048|\n",
      "|    888|    137|     4|879365104|    Big Night (1996)| 4.3304048|\n",
      "|    846|     65|     3|883949254|What's Eating Gil...| 3.5666604|\n",
      "|    392|    255|     3|891038224|My Best Friend's ...| 3.1756823|\n",
      "+-------+-------+------+---------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predicted_ratings_df = cf.model_fit_transform(train_df, test_df) # Fitting the model and getting the predicted ratings \n",
    "predicted_ratings_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9d769b3-f99a-465c-961b-7e0a3d8a051d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1597:(42 + 2) / 44][Stage 1621:>(0 + 2) / 10][Stage 1622:>(0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.8617882602915308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cf.evaluate_recommendation(predicted_ratings_df) # Evaluating the ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca76f5e-2224-4261-aae9-0fceab73ba0e",
   "metadata": {},
   "source": [
    "### Recommendions for new user\n",
    "\n",
    "Here the new user is also sampled from the test data. For the new user we only require some sample rating for items. This can also be done by asking a new user to rate some items/movies that they have already used/seen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a55620c0-42bb-43d8-91ee-0990fd66aa52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "888"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_id = test_df.select('user_id').rdd.flatMap(lambda x:x).take(1)[0] # Sampling a new user id from test data\n",
    "new_user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32f59153-578e-435f-b1bd-e38c48cbbb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+--------------------+\n",
      "|user_id|item_id|rating|timestamp|               title|\n",
      "+-------+-------+------+---------+--------------------+\n",
      "|    888|    100|     4|879365004|        Fargo (1996)|\n",
      "|    888|    111|     4|879365072|Truth About Cats ...|\n",
      "|    888|    237|     5|879365449|Jerry Maguire (1996)|\n",
      "|    888|    274|     4|879365497|      Sabrina (1995)|\n",
      "|    888|     69|     4|879365104| Forrest Gump (1994)|\n",
      "|    888|    137|     4|879365104|    Big Night (1996)|\n",
      "|    888|    153|     4|879365154|Fish Called Wanda...|\n",
      "|    888|    191|     5|879365004|      Amadeus (1984)|\n",
      "|    888|    202|     4|879365072|Groundhog Day (1993)|\n",
      "|    888|    280|     3|879365475|Up Close and Pers...|\n",
      "|    888|    286|     5|879364981|English Patient, ...|\n",
      "|    888|    631|     4|879365224|Crying Game, The ...|\n",
      "|    888|    269|     5|879364981|Full Monty, The (...|\n",
      "|    888|    792|     5|879365054|Bullets Over Broa...|\n",
      "|    888|    869|     4|879365086|Fools Rush In (1997)|\n",
      "|    888|    535|     4|879365497|Addicted to Love ...|\n",
      "|    888|    100|     4|879365004|        Fargo (1996)|\n",
      "|    888|    111|     4|879365072|Truth About Cats ...|\n",
      "|    888|    237|     5|879365449|Jerry Maguire (1996)|\n",
      "|    888|    274|     4|879365497|      Sabrina (1995)|\n",
      "+-------+-------+------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_user_samples = test_df.where(test_df.user_id==new_user_id) # Get all the data for that particular user from test data\n",
    "new_user_samples.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87dbd40e-a342-4b94-9622-cb426223d207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "888"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user = user(new_user_id, new_user_samples) # Initialising a new user object using user class\n",
    "new_user.user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6834775-381f-418a-8119-de0b1c992c68",
   "metadata": {},
   "source": [
    "*Note*: For new user rating predictions, the recommendation system is fitted with the entire data and the sample input ratings collected is passed to the colaborative filtering algorithm to find the ratings for the other items in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6882531-9391-47a5-859b-ef0aba7c96ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------+----------+\n",
      "|item_id|               title|user_id|prediction|\n",
      "+-------+--------------------+-------+----------+\n",
      "|   1449|Pather Panchali (...|    888|  5.181967|\n",
      "|   1467|Saint of Fort Was...|    888| 5.1142607|\n",
      "|   1642|Some Mother's Son...|    888| 5.0453606|\n",
      "|   1398|         Anna (1996)|    888| 5.0294557|\n",
      "|    318|Schindler's List ...|    888|  5.009569|\n",
      "|     64|Shawshank Redempt...|    888| 5.0080843|\n",
      "|   1122|They Made Me a Cr...|    888|  4.966351|\n",
      "|    272|Good Will Hunting...|    888| 4.9331784|\n",
      "|    408|Close Shave, A (1...|    888| 4.8848257|\n",
      "|    483|   Casablanca (1942)|    888| 4.8650794|\n",
      "|    113|Horseman on the R...|    888|  4.839217|\n",
      "|   1064|    Crossfire (1947)|    888| 4.8284464|\n",
      "|    313|      Titanic (1997)|    888| 4.8197722|\n",
      "|     12|Usual Suspects, T...|    888| 4.8181663|\n",
      "|    169|Wrong Trousers, T...|    888|  4.804872|\n",
      "|    603|  Rear Window (1954)|    888| 4.7949753|\n",
      "|    357|One Flew Over the...|    888|  4.794626|\n",
      "|    963|Some Folks Call I...|    888|  4.789891|\n",
      "|     98|Silence of the La...|    888| 4.7826934|\n",
      "|    114|Wallace & Gromit:...|    888|  4.773935|\n",
      "+-------+--------------------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_ratings = cf.new_user_recommendations(new_user) # Predicting ratings for new user\n",
    "new_user.set_predicted_ratings(predicted_ratings) # Setting the predictions in user object\n",
    "new_user.predicted_ratings.show() # Checking the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16e85ce6-4dec-4b81-9d3d-5d16af92cae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pather Panchali (1955)',\n",
       " 'Saint of Fort Washington, The (1993)',\n",
       " \"Some Mother's Son (1996)\",\n",
       " 'Anna (1996)',\n",
       " \"Schindler's List (1993)\",\n",
       " 'Shawshank Redemption, The (1994)',\n",
       " 'They Made Me a Criminal (1939)',\n",
       " 'Good Will Hunting (1997)']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user.get_recommendations(n=8) # Fetching the top 'n' recommended items/movies for that user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912985f1-c2fb-4f46-a427-4637e397d76f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
